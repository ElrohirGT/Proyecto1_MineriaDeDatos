---
title: "CineVision - Clustering, Apriori, PCA"
author: "Flavio Galán, José Prince"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

[Repositorio](https://github.com/ElrohirGT/Proyecto1_MineriaDeDatos.git)

# Clustering

## Prepocesamiento de los datos
```{r}
library(cluster) 
library(hopkins)
library(factoextra)
# install.packages(factoextra)
library(ggplot2)
library(fpc)
library(modeest)

datos <- read.csv("../data/movies.csv")
datos_num <- datos[, sapply(datos, is.numeric)]
datos_num <- datos_num[, -1]
```

Acá podemos encontrar las siguientes variables: **`r colnames(datos)`**. 

Para el análisis de los datos solo se necesitaran de las variables que se categorizaron como cuantitativas durante el análisis exploratorio. Se toma esta decisión debido a que en los métodos de clustering a utilizar se basan en variables cuantitativas por lo que para evitar ambiguedades se omite el agrupamiente de este tipo de variables y obtener un mejor resultado en el agrupamiento de datos. De igual forma otra variable que no aporta información al agrupamiento es justamente la que contiene el id de los datos, en este caso siendo "id", esto se debe a que esta variable al agruparla no aporta ningún tipo de información. 

Obteniendo las siguientes columnas a analizar: **`r colnames(datos_num)`**.

Viendo con más detalle cada una de las variables escogidas.

- budget: el presupuesto utilizado para la película.
- revenue: las ganancias de la película. 
- runtime: duración total de la película.
- popularity: índice de popularidad de la película, calculada semanalmente.
- voteAvg: promedio de votos para la película.
- voteCount: número de votos para la película.
- genresAmount: cantidad total de generos destinados a una película.
- productionCoAmount: cantidad de compañías productoras que participaron en la película.
- productionCountriesAmount: cantidad de países en los que se rodó la película.
- actorsAmount: cantidad de personas que actuan en la película.

## Hopkings y VAT
```{r iniciso 2}
set.seed(123)
hops <- hopkins(datos_num)
cat("Estadistico de Hopkins: ", hops, "\n")
```

Analizando el estadístico de Hopkings obtenemos que su valor es de **1**, esto nos indica que los datos tienen una fuerte estructura de agrupamiento. Para corrobar que existan grupos de datos, se realiza la "Evaluación Visual de Tendencia".

```{r VAT}
datos_dist <- dist(head(datos_num, 300))
fviz_dist(datos_dist, show_labels = F)
```

La EVT (evaluación visuald e tendencia) se hizo con una muestra de 300 debido a que el dataset era muy grande para procesarlo por completo y vemos que existe una tendencia de agrupamiento para los datos.

## Método de codo

```{r Método de codo}
fviz_nbclust(datos_num, kmeans, method = "wss") + ggtitle("Metodo de Codo")
```

Evaluando el dataset con el método de codo se demuestra que es mejor agrupar los datos en un total de 3 grupos para poder obtener la mayor información de cada uno de los grupos de datos. Se hace la elección de 3 grupos debido a que es donde se presenta el mayor cambio de pendiente en la gráfica.

## K-medias y CLustering jerárquico

Este es el gráfico obtenido de K-medias:

```{r K-means}
km <- kmeans(datos_num, 3,iter.max =100)
plotcluster(datos_num, km$cluster)
```

Este es el el dendograma que se genera para el clustering jerárquico:

```{r Agrupamiento jerarquico}
dist_matrix <- dist(datos_num, method = "euclidean")
hc <- hclust(dist_matrix, method = "complete")

plot(hc, main="Dendrograma", xlab="Observaciones", ylab="Distancia")
clusters <- cutree(hc, k=3)
```

Haciendo una comparación entre la gráfica obtenida por K-Means y por el dendograma del agrupamiento jerarquico podemos ver que los datos se separan en tres grupos principales, indicado anteriormente por el método de codo. A su vez podemos ver que uno de los grupos se encuentra más disperso, debido a las limitaciones de software esto no es visible en el dendograma pero sí en K-means.

## Método de la silueta

Este método nos ayudará a determinar la calidad del agrupamiento. Midiendo qué tan bien están agrupados los puntos dentro de su cluster y qué tan separados están de otros clusters. A continuación se muestra el gráfico del método de la silueta para los métodos de clusterings anteriores. 

```{r Silhouette km}
sil <- silhouette(km$cluster, dist(datos_num))
plot(sil, col=1:3, border=NA)

sil <- silhouette(clusters, dist(datos_num))
plot(sil, col=1:3, border=NA)

```

Se puede apreciar que ambos métodos de clustering agrupan correctamente cada punto en su respectivo cluster. Esto lo sabemos cuando vemos el valor de "average silhouette width" que es 0.8 y 0.93 para K-means y hc (hierarchy clustering); si este valor hubiera sido cercano a 0 nos indicaria que el clustering no es muy claro o no esta bien definido, en caso de ser un número negativo sugiere que la asignación de los clusters podría ser incorrecta. Ya simplemente comparando los "average silhouette width" entre los diferentes métodos vemos que el hc es el mejor método.

## Interpretación de los grupos

```{r groups table}
datos_num$grupo <- as.factor(clusters)
aggregate(datos_num[, -ncol(datos_num)], by = list(datos_num$grupo), FUN = mean)
```
Se hizo la separación de los datos en tres grupos como lo recomendaba el método de codo. En la tabla anterior podemos ver como se comporta cada variable en su respectivo cluster, mostrando la media de las variables. Inicialmente con repecto al presupuesto podemos ver 3 distintos valores pero los valores del grupo 2 y 3 no se alejan tanto como si lo hace el valor del grupo 1, estoy puede indicar la cantidad de presupuesto de la pelicula siendo el grupo 1 peliculas con presupuesto bajo y el grupo 2 y 3 con un presupuesto moderado/alto. Se puede ver que en relación al presupuesto invertido la pelicula es más popular, dando a entender que aquellas peliculas que se les otorga un mayor presupuesto pueden ser secuelas o franquicias famosas. Igualmente vemos que las peliculas al ser menos famosas, teniendo un presupuesto bajo se afirma que a su vez menos gente las conoce y por ende tiene menos calificaciones. Es interesante ver que se aprecia una tendencia en que a mayor presupuesto, se tiene una mayor duración; esto indica que la duración de la pelicula se puede dar por muchos factores pero que la cantidad de dinero en producción determina que tan larga puede ser esta.  En las demás categorias se pueden ver muchas similitudes entre en cada uno de los grupos como en la cantidad de géneros o la cantidad de países en donde se rodó la película. Esto es el análisis que se le pudo sacar a los datos en base a las variables analizadas.

# Reglas de Asociación
Obtenga reglas de asociación interesantes del conjunto de datos usando el algoritmo “A
priori”. Recuerde discretizar las variables numéricas. Genere reglas con diferentes niveles
de confianza y soporte. Discuta los resultados. Si considera que debe eliminar variables porque son muy frecuentes y con eso puede recibir más “insights” de la generación de
reglas. Hágalo y discútalo.

```{r}
#install.packages("arules")      # Para ejecutar el algoritmo Apriori
#install.packages("arulesViz")   # Para visualizar las reglas de asociación
library(arules)
library(arulesViz)

datos <- read.csv("../data/movies.csv")

datos$budget <- cut(datos$budget, breaks = 5, labels = c("Muy Bajo", "Bajo", "Medio", "Alto", "Muy Alto"))
datos$revenue <- cut(datos$revenue, breaks = 5, labels = c("Muy Bajo", "Bajo", "Medio", "Alto", "Muy Alto"))
datos$runtime <- cut(datos$runtime, breaks = 3, labels = c("Corto", "Medio", "Largo"))
datos$popularity <- cut(datos$popularity, breaks = 4, labels = c("Baja", "Media", "Alta", "Muy Alta"))
datos$voteAvg <- cut(datos$voteAvg, breaks = 3, labels = c("Mala", "Regular", "Buena"))
datos$voteCount <- cut(datos$voteCount, breaks = 4, labels = c("Pocos", "Moderados", "Muchos", "Masivos"))

datos <- datos[c("budget", "revenue", "runtime", "popularity", "voteAvg", "voteCount")]

# Convertir a transacciones
datos_trans <- as(datos, "transactions")

reglas <- apriori(datos_trans, parameter = list(supp = 0.01, conf = 0.8, minlen=2))

#inspect(reglas)
inspect(sort(reglas, by = "lift", decreasing = TRUE))

```
Como se puede ver encuentra muchas reglas dentro del conjunto de datos, sin embargo, varias son subconjuntos de otras reglas que se pueden encontrar más abajo. Lo que lleva a muchas repeticiones.

Algunas reglas interesantes que pude encontrar son por ejemplo:

* Tener un Budget muy bajo, una popularidad baja pero un voteCount moderado generalmente lleva a un voteAvg bueno! Esta regla se cumple con casi un 90% de confianza y tiene un soporte del 0.0114 en todo el dataset. El soporte puede ser bajo pero es que justamente la regla está hablando de películas underground que normalmente pasan desapercibidas.

* Aunque tengas un budget muy bajo y un runtime corto si tu popularidad tambiés es baja no importa que tu average de votos sea bueno, la data predice que tu revenue será muy bajo con un 99% de confianza y un 0.23 de representación. Por lo tanto esto nos dice que la popularidad es importante!

# PCA

**3.1. Estudie si es posible hacer transformaciones en las variables categóricas para incluirlas en
el PCA, ¿valdrá la pena?**

Sí se puede realizar PCA en variables categóricas aunque solamente si éstas son traducibles a números ordenados, si en su lugar se tienen propiedades como: "verde", "rojo", "azul" y no implican un orden entre ellas entonces no es posible.

Dentro de las variables que tenemos en el data set de películas, ninguna se puede traducir a números ordenados puesto que las variables no son ordenadas.


**3.2. Estudie si es conveniente hacer un Análisis de Componentes Principales. Recuerde que puede usar el índice KMO y el test de esfericidad de Bartlett.**

```{r}
library(psych)
library(corpcor)
library(nFactors)

datos <- read.csv("../data/movies.csv")
datos_num <- datos[, sapply(datos, is.numeric)]

kmo_result <- KMO(cor(datos_num))
print(kmo_result)

bartlett_result <- cortest.bartlett(cor(datos_num), n = nrow(datos_num))
print(bartlett_result)
```

Según los índices KMO la mayoría de variables son buenas o excelentes para aplicar PCA con la excepción de voteAvg. La prueba de Bartlett nos dice que efectivamente la matriz de correlación no es una matriz de identidad por lo tanto hay correlaciones significativas en la data. 

**3.3. Haga un análisis de componentes principales con las variables numéricas, discuta los
resultados e interprete los componentes.**

```{r}
# Instalar y cargar los paquetes necesarios
# install.packages("factoextra")  # Para visualización de PCA
# install.packages("ggplot2")      # Para gráficos adicionales
library(psych)
#library(factoextra)
library(ggplot2)

# Estandarización de los datos (importante para PCA)
datos_pca_scaled <- scale(datos_num)

# Aplicar PCA
pca_result <- prcomp(datos_pca_scaled, center = TRUE, scale = TRUE)

# Resumen del PCA
summary(pca_result)

# Visualización de la varianza explicada
fviz_eig(pca_result) 

# Biplot de las dos primeras componentes principales
fviz_pca_biplot(pca_result, repel = TRUE, col.var = "blue", col.ind = "red")

# Gráfico de contribución de las variables a la primera componente principal
fviz_contrib(pca_result, choice = "var", axes = 1)

# Gráfico de contribución de las variables a la segunda componente principal
fviz_contrib(pca_result, choice = "var", axes = 2)

```
Como se puede ver por el resultado del PCA, se puede explicar más del 70% de la varianza usando las primeras 6 variables. Obteniendo las cargas factoriales tenemos:
```{r}
loadings <- pca_result$rotation[,1:6]
print(loadings)
```

PC1: Budget, Revenue, VoteCount
PC2: Id, Popularity, ActorsAmount
PC3: ProductionCountriesAmount, Runtime, VoteAVG
PC4: VoteAVG, ProductionCountriesAmount
PC5: GenresAmount, ProductionCoAmount
PC6: ActorsAmount, ProductionCountriesAmount

No todas las variables que da como resultado el PCA tienen un sentido puesto que realmente es solo una forma de minimizar el espacio en el que estamos trabajando los datos. Sin embargo algunas interpretaciones que veo por las componentes principales de cada variable superior son:

* PC1: Éxito Financiero de una película
* PC5: Qué tan amigable al público general es la película

# Conclusiones

El clustering de los datos nos indicó que es óptimo separar el conjunto de datos en 3 grupos:

* Group 1: Identificado principalmente por su baja cantidad de dinero presupuestado, en general represeta al conjunto de películas independientes u _underground_.
* Grupo 3: Representa a todos los blockbusters del cine, proyectos/franquicias enormes con una gran cantidad de presupuesto y en general, duración y cuenta de votos más altos.
* Grupo 2: El grupo dos representa todas las películas con presupuesto medio/alto cuya principal diferencia respecto al grupo 3 es su popularidad, pues su media es de lejos la más alta en este aspecto.

Pasando al análisis de componentes principales o PCA podemos afirmar que 6 u 8 es el número ideal para la reducción, en este análisis se decidió usar 6 representando así más del 70% de la variabilidad de los datos. Muchas de las variables generadas por el PCA fueron realmente combinaciones lineales solamente sin un claro significado en el mundo real, sin embargo se pudieron encontrar 2 variables que sería interesante explorar más a fondo en otro análisis a futuro:

* PC1: Representando el éxito financiero de una película.
* PC5: Qué tan amigable al público general es la película.

Regresando al análisis a priori que genera reglas en base a los datos, las dos más interesantes fueron:

* Tener un Budget muy bajo, una popularidad baja pero un voteCount moderado generalmente lleva a un voteAvg bueno! Esta regla se cumple con casi un 90% de confianza y tiene un soporte del 0.0114 en todo el dataset. El soporte puede ser bajo pero es que justamente la regla está hablando de películas underground que normalmente pasan desapercibidas.

* Si tienes un budget muy bajo y un runtime corto no importa que consigas un average de votos bueno, si no logras subir tu popularidad, la data predice que tu revenue será muy bajo con un 99% de confianza y un 0.23 de representación. Por lo tanto esto nos dice que la popularidad es importante!


Finalmente nuestras sugerencias principales a CineVisión serían:

* La popularidad de una película es un factor clave en el éxito en revenue obtenido de un proyecto! No escatimen en el marketing y el desarrollo de una historia/proyecto de calidad aunque tengan un budget bajo.
* Solo hay 3 grupos de proyectos dentro de los datos, existen varias estrategias para entrar a distintas secciones del mercado, intenta enfocarte en uno de los 3 sub-mercados y recuerda, es mejor ser cabeza de ratón que cola de león.
* En futuros análisis recomendamos investigar cómo se representa el éxito financier de una película respecto a qué tan amigable es para el público general, pueden usar la misma minimización de PCA que utilizamos en este estudio.